@inproceedings{van-miltenburg-etal-2021-underreporting,
    title = "Underreporting of errors in {NLG} output, and what to do about it",
    author = {van Miltenburg, Emiel  and
      Clinciu, Miruna  and
      Du{\v{s}}ek, Ond{\v{r}}ej  and
      Gkatzia, Dimitra  and
      Inglis, Stephanie  and
      Lepp{\"a}nen, Leo  and
      Mahamood, Saad  and
      Manning, Emma  and
      Schoch, Stephanie  and
      Thomson, Craig  and
      Wen, Luou},
    booktitle = "Proceedings of the 14th International Conference on Natural Language Generation",
    month = aug,
    year = "2021",
    address = "Aberdeen, Scotland, UK",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.inlg-1.14",
    pages = "140--153",
    abstract = "We observe a severe under-reporting of the different kinds of errors that Natural Language Generation systems make. This is a problem, because mistakes are an important indicator of where systems should still be improved. If authors only report overall performance metrics, the research community is left in the dark about the specific weaknesses that are exhibited by {`}state-of-the-art{'} research. Next to quantifying the extent of error under-reporting, this position paper provides recommendations for error identification, analysis and reporting.",
}

@inproceedings{schoch-etal-2021-contextualizing,
    title = "Contextualizing Variation in Text Style Transfer Datasets",
    author = "Schoch, Stephanie  and
      Du, Wanyu  and
      Ji, Yangfeng",
    booktitle = "Proceedings of the 14th International Conference on Natural Language Generation",
    month = aug,
    year = "2021",
    address = "Aberdeen, Scotland, UK",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.inlg-1.22",
    pages = "226--239",
    abstract = "Text style transfer involves rewriting the content of a source sentence in a target style. Despite there being a number of style tasks with available data, there has been limited systematic discussion of how text style datasets relate to each other. This understanding, however, is likely to have implications for selecting multiple data sources for model training. While it is prudent to consider inherent stylistic properties when determining these relationships, we also must consider how a style is realized in a particular dataset. In this paper, we conduct several empirical analyses of existing text style datasets. Based on our results, we propose a categorization of stylistic and dataset properties to consider when utilizing or comparing text style datasets.",
}

@inproceedings{schoch-etal-2020-problem,
    title = "{``}This is a Problem, Don{'}t You Agree?{''} Framing and Bias in Human Evaluation for Natural Language Generation",
    author = "Schoch, Stephanie  and
      Yang, Diyi  and
      Ji, Yangfeng",
    booktitle = "Proceedings of the 1st Workshop on Evaluating NLG Evaluation",
    month = dec,
    year = "2020",
    address = "Online (Dublin, Ireland)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.evalnlgeval-1.2",
    pages = "10--16",
    abstract = "Despite recent efforts reviewing current human evaluation practices for natural language generation (NLG) research, the lack of reported question wording and potential for framing effects or cognitive biases influencing results has been widely overlooked. In this opinion paper, we detail three possible framing effects and cognitive biases that could be imposed on human evaluation in NLG. Based on this, we make a call for increased transparency for human evaluation in NLG and propose the concept of human evaluation statements. We make several recommendations for design details to report that could potentially influence results, such as question wording, and suggest that reporting pertinent design details can help increase comparability across studies as well as reproducibility of results.",
}
